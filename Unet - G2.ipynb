{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as K\n",
    "\n",
    "K.set_image_dim_ordering('tf')  # Tensor Flow dimension ordering in this code\n",
    "img_rows = 64\n",
    "img_cols = 80\n",
    "\n",
    "smooth = 1.\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:19: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/ubuntu/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:20: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Creating training images...\n",
      "------------------------------\n",
      "Done: 0/5635.0 images\n",
      "Done: 100/5635.0 images\n",
      "Done: 200/5635.0 images\n",
      "Done: 300/5635.0 images\n",
      "Done: 400/5635.0 images\n",
      "Done: 500/5635.0 images\n",
      "Done: 600/5635.0 images\n",
      "Done: 700/5635.0 images\n",
      "Done: 800/5635.0 images\n",
      "Done: 900/5635.0 images\n",
      "Done: 1000/5635.0 images\n",
      "Done: 1100/5635.0 images\n",
      "Done: 1200/5635.0 images\n",
      "Done: 1300/5635.0 images\n",
      "Done: 1400/5635.0 images\n",
      "Done: 1500/5635.0 images\n",
      "Done: 1600/5635.0 images\n",
      "Done: 1700/5635.0 images\n",
      "Done: 1800/5635.0 images\n",
      "Done: 1900/5635.0 images\n",
      "Done: 2000/5635.0 images\n",
      "Done: 2100/5635.0 images\n",
      "Done: 2200/5635.0 images\n",
      "Done: 2300/5635.0 images\n",
      "Done: 2400/5635.0 images\n",
      "Done: 2500/5635.0 images\n",
      "Done: 2600/5635.0 images\n",
      "Done: 2700/5635.0 images\n",
      "Done: 2800/5635.0 images\n",
      "Done: 2900/5635.0 images\n",
      "Done: 3000/5635.0 images\n",
      "Done: 3100/5635.0 images\n",
      "Done: 3200/5635.0 images\n",
      "Done: 3300/5635.0 images\n",
      "Done: 3400/5635.0 images\n",
      "Done: 3500/5635.0 images\n",
      "Done: 3600/5635.0 images\n",
      "Done: 3700/5635.0 images\n",
      "Done: 3800/5635.0 images\n",
      "Done: 3900/5635.0 images\n",
      "Done: 4000/5635.0 images\n",
      "Done: 4100/5635.0 images\n",
      "Done: 4200/5635.0 images\n",
      "Done: 4300/5635.0 images\n",
      "Done: 4400/5635.0 images\n",
      "Done: 4500/5635.0 images\n",
      "Done: 4600/5635.0 images\n",
      "Done: 4700/5635.0 images\n",
      "Done: 4800/5635.0 images\n",
      "Done: 4900/5635.0 images\n",
      "Done: 5000/5635.0 images\n",
      "Done: 5100/5635.0 images\n",
      "Done: 5200/5635.0 images\n",
      "Done: 5300/5635.0 images\n",
      "Done: 5400/5635.0 images\n",
      "Done: 5500/5635.0 images\n",
      "Done: 5600/5635.0 images\n",
      "Loading done.\n",
      "Saving to .npy files done.\n",
      "------------------------------\n",
      "Creating test images...\n",
      "------------------------------\n",
      "Done: 0/5508 images\n",
      "Done: 100/5508 images\n",
      "Done: 200/5508 images\n",
      "Done: 300/5508 images\n",
      "Done: 400/5508 images\n",
      "Done: 500/5508 images\n",
      "Done: 600/5508 images\n",
      "Done: 700/5508 images\n",
      "Done: 800/5508 images\n",
      "Done: 900/5508 images\n",
      "Done: 1000/5508 images\n",
      "Done: 1100/5508 images\n",
      "Done: 1200/5508 images\n",
      "Done: 1300/5508 images\n",
      "Done: 1400/5508 images\n",
      "Done: 1500/5508 images\n",
      "Done: 1600/5508 images\n",
      "Done: 1700/5508 images\n",
      "Done: 1800/5508 images\n",
      "Done: 1900/5508 images\n",
      "Done: 2000/5508 images\n",
      "Done: 2100/5508 images\n",
      "Done: 2200/5508 images\n",
      "Done: 2300/5508 images\n",
      "Done: 2400/5508 images\n",
      "Done: 2500/5508 images\n",
      "Done: 2600/5508 images\n",
      "Done: 2700/5508 images\n",
      "Done: 2800/5508 images\n",
      "Done: 2900/5508 images\n",
      "Done: 3000/5508 images\n",
      "Done: 3100/5508 images\n",
      "Done: 3200/5508 images\n",
      "Done: 3300/5508 images\n",
      "Done: 3400/5508 images\n",
      "Done: 3500/5508 images\n",
      "Done: 3600/5508 images\n",
      "Done: 3700/5508 images\n",
      "Done: 3800/5508 images\n",
      "Done: 3900/5508 images\n",
      "Done: 4000/5508 images\n",
      "Done: 4100/5508 images\n",
      "Done: 4200/5508 images\n",
      "Done: 4300/5508 images\n",
      "Done: 4400/5508 images\n",
      "Done: 4500/5508 images\n",
      "Done: 4600/5508 images\n",
      "Done: 4700/5508 images\n",
      "Done: 4800/5508 images\n",
      "Done: 4900/5508 images\n",
      "Done: 5000/5508 images\n",
      "Done: 5100/5508 images\n",
      "Done: 5200/5508 images\n",
      "Done: 5300/5508 images\n",
      "Done: 5400/5508 images\n",
      "Done: 5500/5508 images\n",
      "Loading done.\n",
      "Saving to .npy files done.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "\n",
    "data_path = '/home/ubuntu/midterm/raw/'\n",
    "\n",
    "image_rows = 420\n",
    "image_cols = 580\n",
    "\n",
    "\n",
    "def create_train_data():\n",
    "    train_data_path = os.path.join(data_path, 'train')\n",
    "    images = os.listdir(train_data_path)\n",
    "    total = len(images) / 2\n",
    "\n",
    "    imgs = np.ndarray((total, 1, image_rows, image_cols), dtype=np.uint8)\n",
    "    imgs_mask = np.ndarray((total, 1, image_rows, image_cols), dtype=np.uint8)\n",
    "\n",
    "    i = 0\n",
    "    print('-'*30)\n",
    "    print('Creating training images...')\n",
    "    print('-'*30)\n",
    "    for image_name in images:\n",
    "        if 'mask' in image_name:\n",
    "            continue\n",
    "        image_mask_name = image_name.split('.')[0] + '_mask.tif'\n",
    "        img = cv2.imread(os.path.join(train_data_path, image_name), cv2.IMREAD_GRAYSCALE)\n",
    "        img_mask = cv2.imread(os.path.join(train_data_path, image_mask_name), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        img = np.array([img])\n",
    "        img_mask = np.array([img_mask])\n",
    "\n",
    "        imgs[i] = img\n",
    "        imgs_mask[i] = img_mask\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('Done: {0}/{1} images'.format(i, total))\n",
    "        i += 1\n",
    "    print('Loading done.')\n",
    "\n",
    "    np.save('imgs_train.npy', imgs)\n",
    "    np.save('imgs_mask_train.npy', imgs_mask)\n",
    "    print('Saving to .npy files done.')\n",
    "\n",
    "\n",
    "def load_train_data():\n",
    "    imgs_train = np.load('imgs_train.npy')\n",
    "    imgs_mask_train = np.load('imgs_mask_train.npy')\n",
    "    return imgs_train, imgs_mask_train\n",
    "\n",
    "\n",
    "def create_test_data():\n",
    "    train_data_path = os.path.join(data_path, 'test')\n",
    "    images = os.listdir(train_data_path)\n",
    "    total = len(images)\n",
    "\n",
    "    imgs = np.ndarray((total, 1, image_rows, image_cols), dtype=np.uint8)\n",
    "    imgs_id = np.ndarray((total, ), dtype=np.int32)\n",
    "\n",
    "    i = 0\n",
    "    print('-'*30)\n",
    "    print('Creating test images...')\n",
    "    print('-'*30)\n",
    "    for image_name in images:\n",
    "        img_id = int(image_name.split('.')[0])\n",
    "        img = cv2.imread(os.path.join(train_data_path, image_name), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        img = np.array([img])\n",
    "\n",
    "        imgs[i] = img\n",
    "        imgs_id[i] = img_id\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('Done: {0}/{1} images'.format(i, total))\n",
    "        i += 1\n",
    "    print('Loading done.')\n",
    "\n",
    "    np.save('imgs_test.npy', imgs)\n",
    "    np.save('imgs_id_test.npy', imgs_id)\n",
    "    print('Saving to .npy files done.')\n",
    "\n",
    "\n",
    "def load_test_data():\n",
    "    imgs_test = np.load('imgs_test.npy')\n",
    "    imgs_id = np.load('imgs_id_test.npy')\n",
    "    return imgs_test, imgs_id\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    create_train_data()\n",
    "    create_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_train_data():\n",
    "    imgs_train = np.load('imgs_train.npy')\n",
    "    imgs_mask_train = np.load('imgs_mask_train.npy')\n",
    "    return imgs_train, imgs_mask_train\n",
    "\n",
    "def load_test_data():\n",
    "    imgs_test = np.load('imgs_test.npy')\n",
    "    imgs_id = np.load('imgs_id_test.npy')\n",
    "    return imgs_test, imgs_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "def get_unet():\n",
    "    from keras.utils.layer_utils import print_summary\n",
    "    inputs = Input((1, img_rows, img_cols))\n",
    "    dropout1 = Dropout(0.25)(inputs)\n",
    "    conv1 = Convolution2D(32, 3, 3, activation='relu', border_mode='same',dim_ordering='th')(dropout1)\n",
    "    conv1 = Convolution2D(32, 3, 3, activation='relu', border_mode='same',dim_ordering='th')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2),dim_ordering='th')(conv1)\n",
    "    #imshow(l.activation(inpic)) \n",
    "\n",
    "    #dropout2 = Dropout(0.25)(pool1)\n",
    "    conv2 = Convolution2D(64, 3, 3, activation='relu', border_mode='same',dim_ordering='th')(pool1)\n",
    "    conv2 = Convolution2D(64, 3, 3, activation='relu', border_mode='same',dim_ordering='th')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2),dim_ordering=\"th\")(conv2)\n",
    "\n",
    "    #dropout3 = Dropout(0.25)(pool2)\n",
    "    conv3 = Convolution2D(128, 3, 3, activation='relu', border_mode='same',dim_ordering='th')(pool2)\n",
    "    conv3 = Convolution2D(128, 3, 3, activation='relu', border_mode='same',dim_ordering='th')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2),dim_ordering=\"th\")(conv3)\n",
    "\n",
    "    #dropout4 = Dropout(0.25)(pool3)\n",
    "    conv4 = Convolution2D(256, 3, 3, activation='relu', border_mode='same',dim_ordering='th')(pool3)\n",
    "    conv4 = Convolution2D(256, 3, 3, activation='relu', border_mode='same',dim_ordering='th')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2),dim_ordering=\"th\")(conv4)\n",
    "\n",
    "    #dropout5 = Dropout(0.25)(pool4)\n",
    "    conv5 = Convolution2D(512, 3, 3, activation='relu', border_mode='same',dim_ordering='th')(pool4)\n",
    "    conv5 = Convolution2D(512, 3, 3, activation='relu', border_mode='same',dim_ordering='th')(conv5)\n",
    "\n",
    "    up6 = merge([UpSampling2D(size=(2, 2),dim_ordering='th')(conv5), conv4], mode='concat', concat_axis=1)\n",
    "    conv6 = Convolution2D(256, 3, 3, activation='relu', border_mode='same',dim_ordering='th')(up6)\n",
    "    conv6 = Convolution2D(256, 3, 3, activation='relu', border_mode='same',dim_ordering='th')(conv6)\n",
    "\n",
    "    up7 = merge([UpSampling2D(size=(2, 2),dim_ordering='th')(conv6), conv3], mode='concat', concat_axis=1)\n",
    "    conv7 = Convolution2D(128, 3, 3, activation='relu', border_mode='same',dim_ordering='th')(up7)\n",
    "    conv7 = Convolution2D(128, 3, 3, activation='relu', border_mode='same',dim_ordering='th')(conv7)\n",
    "\n",
    "    up8 = merge([UpSampling2D(size=(2, 2),dim_ordering='th')(conv7), conv2], mode='concat', concat_axis=1)\n",
    "    conv8 = Convolution2D(64, 3, 3, activation='relu', border_mode='same',dim_ordering='th')(up8)\n",
    "    conv8 = Convolution2D(64, 3, 3, activation='relu', border_mode='same',dim_ordering='th')(conv8)\n",
    "\n",
    "    up9 = merge([UpSampling2D(size=(2, 2),dim_ordering='th')(conv8), conv1], mode='concat', concat_axis=1)\n",
    "    conv9 = Convolution2D(32, 3, 3, activation='relu', border_mode='same',dim_ordering='th')(up9)\n",
    "    conv9 = Convolution2D(32, 3, 3, activation='relu', border_mode='same',dim_ordering='th')(conv9)\n",
    "\n",
    "    conv10 = Convolution2D(1, 1, 1, activation='sigmoid',dim_ordering='th')(conv9)\n",
    "\n",
    "    model = Model(input=inputs, output=conv10)\n",
    "    \n",
    "    #model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "\n",
    "    #model.compile(optimizer='adam', loss=dice_coef_loss, metrics=[dice_coef])\n",
    "    #sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    \n",
    "    #rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08)\n",
    "    #model.compile(optimizer=rmsprop, loss='binary_crossentropy')\n",
    "    #model.compile(optimizer=rmsprop, loss='binary_crossentropy')\n",
    "    model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "    #metrics={'outbin': 'accuracy'}\n",
    "    \n",
    "    #model.compile(optimizer='adam', loss='binary_crossentropy',metrics=[dice_coef])\n",
    "\n",
    "    print_summary(model.layers)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "img_rows = 64\n",
    "img_cols = 80\n",
    "\n",
    "smooth = 1.\n",
    "\n",
    "def preprocess(imgs):\n",
    "    imgs_p = np.ndarray((imgs.shape[0], imgs.shape[1], img_rows, img_cols), dtype=np.uint8)\n",
    "    for i in range(imgs.shape[0]):\n",
    "        imgs_p[i, 0] = cv2.resize(imgs[i, 0], (img_cols, img_rows), interpolation=cv2.INTER_CUBIC)\n",
    "    return imgs_p\n",
    "\n",
    "\n",
    "def train_and_predict():\n",
    "    print('-'*30)\n",
    "    print('Loading and preprocessing train data...')\n",
    "    print('-'*30)\n",
    "    imgs_train, imgs_mask_train = load_train_data()\n",
    "\n",
    "    imgs_train = preprocess(imgs_train)\n",
    "    imgs_mask_train = preprocess(imgs_mask_train)\n",
    "\n",
    "    imgs_train = imgs_train.astype('float32')\n",
    "    mean = np.mean(imgs_train)  # mean for data centering\n",
    "    std = np.std(imgs_train)  # std for data normalization\n",
    "\n",
    "    imgs_train -= mean\n",
    "    imgs_train /= std\n",
    "\n",
    "    imgs_mask_train = imgs_mask_train.astype('float32')\n",
    "    imgs_mask_train /= 255.  # scale masks to [0, 1]\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Creating and compiling model...')\n",
    "    print('-'*30)\n",
    "    model = get_unet()\n",
    "    model_checkpoint = ModelCheckpoint('unet.hdf5_unet', monitor='loss', save_best_only=True)\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Fitting model...')\n",
    "    print('-'*30)\n",
    "    model.fit(imgs_train, imgs_mask_train, batch_size=32, nb_epoch=500, verbose=1, shuffle=True,\n",
    "              callbacks=[model_checkpoint])\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Loading and preprocessing test data...')\n",
    "    print('-'*30)\n",
    "    imgs_test, imgs_id_test = load_test_data()\n",
    "    imgs_test = preprocess(imgs_test)\n",
    "\n",
    "    imgs_test = imgs_test.astype('float32')\n",
    "    imgs_test -= mean\n",
    "    imgs_test /= std\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Loading saved weights...')\n",
    "    print('-'*30)\n",
    "    model.load_weights('unet.hdf5_unet')\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Predicting masks on test data...')\n",
    "    print('-'*30)\n",
    "    imgs_mask_test = model.predict(imgs_test, verbose=1)\n",
    "    np.save('imgs_mask_test_unet.npy', imgs_mask_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs_train = np.load('imgs_train.npy')\n",
    "imgs_mask_train = np.load('imgs_mask_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imgs_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-73d3d357b51c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimgs_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'imgs_train' is not defined"
     ]
    }
   ],
   "source": [
    "imgs_train.shape[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D,Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as K\n",
    "train_and_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Loading and preprocessing train data...\n",
      "------------------------------\n",
      "------------------------------\n",
      "Creating and compiling model...\n",
      "------------------------------\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_4 (InputLayer)             (None, 1, 64, 80)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 1, 64, 80)     0           input_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_39 (Convolution2D) (None, 32, 64, 80)    320         dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_40 (Convolution2D) (None, 32, 64, 80)    9248        convolution2d_39[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_9 (MaxPooling2D)    (None, 32, 32, 40)    0           convolution2d_40[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_41 (Convolution2D) (None, 64, 32, 40)    18496       maxpooling2d_9[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_42 (Convolution2D) (None, 64, 32, 40)    36928       convolution2d_41[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_10 (MaxPooling2D)   (None, 64, 16, 20)    0           convolution2d_42[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_43 (Convolution2D) (None, 128, 16, 20)   73856       maxpooling2d_10[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_44 (Convolution2D) (None, 128, 16, 20)   147584      convolution2d_43[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_11 (MaxPooling2D)   (None, 128, 8, 10)    0           convolution2d_44[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_45 (Convolution2D) (None, 256, 8, 10)    295168      maxpooling2d_11[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_46 (Convolution2D) (None, 256, 8, 10)    590080      convolution2d_45[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_12 (MaxPooling2D)   (None, 256, 4, 5)     0           convolution2d_46[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_47 (Convolution2D) (None, 512, 4, 5)     1180160     maxpooling2d_12[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_48 (Convolution2D) (None, 512, 4, 5)     2359808     convolution2d_47[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "upsampling2d_9 (UpSampling2D)    (None, 512, 8, 10)    0           convolution2d_48[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "merge_9 (Merge)                  (None, 768, 8, 10)    0           upsampling2d_9[0][0]             \n",
      "                                                                   convolution2d_46[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_49 (Convolution2D) (None, 256, 8, 10)    1769728     merge_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_50 (Convolution2D) (None, 256, 8, 10)    590080      convolution2d_49[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "upsampling2d_10 (UpSampling2D)   (None, 256, 16, 20)   0           convolution2d_50[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "merge_10 (Merge)                 (None, 384, 16, 20)   0           upsampling2d_10[0][0]            \n",
      "                                                                   convolution2d_44[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_51 (Convolution2D) (None, 128, 16, 20)   442496      merge_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_52 (Convolution2D) (None, 128, 16, 20)   147584      convolution2d_51[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "upsampling2d_11 (UpSampling2D)   (None, 128, 32, 40)   0           convolution2d_52[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "merge_11 (Merge)                 (None, 192, 32, 40)   0           upsampling2d_11[0][0]            \n",
      "                                                                   convolution2d_42[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_53 (Convolution2D) (None, 64, 32, 40)    110656      merge_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_54 (Convolution2D) (None, 64, 32, 40)    36928       convolution2d_53[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "upsampling2d_12 (UpSampling2D)   (None, 64, 64, 80)    0           convolution2d_54[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "merge_12 (Merge)                 (None, 96, 64, 80)    0           upsampling2d_12[0][0]            \n",
      "                                                                   convolution2d_40[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_55 (Convolution2D) (None, 32, 64, 80)    27680       merge_12[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_56 (Convolution2D) (None, 32, 64, 80)    9248        convolution2d_55[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_57 (Convolution2D) (None, 1, 64, 80)     33          convolution2d_56[0][0]           \n",
      "====================================================================================================\n",
      "Total params: 7846081\n",
      "____________________________________________________________________________________________________\n",
      "------------------------------\n",
      "Fitting model...\n",
      "------------------------------\n",
      "Epoch 1/500\n",
      "5635/5635 [==============================] - 1229s - loss: -0.1232 - dice_coef: 0.1232  \n",
      "Epoch 2/500\n",
      "5635/5635 [==============================] - 1395s - loss: -0.2384 - dice_coef: 0.2384  \n",
      "Epoch 3/500\n",
      "1312/5635 [=====>........................] - ETA: 1085s - loss: -0.2508 - dice_coef: 0.2508"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D,Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as K\n",
    "train_and_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5120"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_mask_test = np.load(\"imgs_mask_test.npy\")\n",
    "imgs_test = np.load(\"imgs_test.npy\")\n",
    "img_mask_test.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
